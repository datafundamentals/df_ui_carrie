/*
Copyright 2014 <%= datasource.authorName %>

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
 
This file generated by <%= datasource.authorName %> via 'Carrie' UI
 */


package com.datafundamentals.refactorme;

import org.apache.camel.builder.RouteBuilder;

/**
 * A Camel Java DSL Router - generated by <%= datasource.authorName %> via 'Carrie' UI
 */
public class MyRouteBuilder extends RouteBuilder {
     
    public void configure() {
//
// copy any data files which appear in the ETL drop folder to processing folder to run toAvro
        from("file:<%= datasource.serverHome %>/<%= datasource.etlDropFolder %>/<%= datasource.uniqueName %>?noop=true")
        .log("copied file for avro transformation: ${in.header.CamelFileName}")
		.to("file:<%= datasource.serverHome %>/<%= datasource.etlDropFolder %>/<%= datasource.uniqueName %>/transform");

// run toAvro and create new avro files
        from("file:<%= datasource.serverHome %>/<%= datasource.etlDropFolder %>/<%= datasource.uniqueName %>/transform?include=.*.csv")
        .log("toAvro transformation: ${in.header.CamelFileName}")
		.to("avroetl:abar?outputFilePath=<%= datasource.serverHome %>/<%= datasource.etlDropFolder %>/<%= datasource.uniqueName %>/transform/<%= datasource.tableName %>&delimiter=,&exceptionOnBadData=false&className=<%= datasource.className %>&namespace=<%= datasource.packageName %>");
		
//now, move newly created avro files back to ETL drop folder
//        from("file:<%= datasource.serverHome %>/<%= datasource.etlDropFolder %>/<%= datasource.uniqueName %>/transform")
//        .log("moved file after avro transformation: ${in.header.CamelFileName}")
//        .to("sftp://<%= datasource.hadoopVmUserName %>@<%= datasource.hadoopVmSshIpAddress %>:2222/<%= datasource.ftpTargetDir %>/<%= datasource.uniqueName %>?password=<%= datasource.hadoopVmPassword %>");	

//copy all files to the hadoop server input folder
//        from("file:<%= datasource.serverHome %>/<%= datasource.etlDropFolder %>/<%= datasource.uniqueName %>?noop=true")
//        .log("copied all files to server: ${in.header.CamelFileName}")
//        .to("sftp://<%= datasource.hadoopVmUserName %>@<%= datasource.hadoopVmSshIpAddress %>:/<%= datasource.ftpTargetDir %>/<%= datasource.uniqueName %>?password=<%= datasource.hadoopVmPassword %>");	
        
// move the program files too - these should only move first time, after that this should not have any effect
//        from("file:bin?noop=true")
//        .to("sftp://<%= datasource.hadoopVmUserName %>@<%= datasource.hadoopVmSshIpAddress %>:/<%= datasource.ftpTargetDir %>/<%= datasource.uniqueName %>?password=<%= datasource.hadoopVmPassword %>");
        
// run hive commands to inject data from the hadoop vm into the hive tables
//        from("timer:foo?period=10000")
//        .setBody(constant("./runhive.sh"))
//        .to("ssh://<%= datasource.hadoopVmUserName %>@<%= datasource.hadoopVmSshIpAddress %>?password=<%= datasource.hadoopVmPassword %>&useFixedDelay=true&delay=5000")
//        .to("log:org.apache.camel.builder.MyRouteBuilder?showAll=true&multiline=true");
    }
}
